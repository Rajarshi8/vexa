# VEXA AI Agent

ğŸ¤– **VEXA** is a powerful, privacy-focused, and fully offline-capable AI Agent designed to perform intelligent tasks such as answering queries, searching the web, and using custom tools. Built using LangChain, Ollama, and DuckDuckGo, it utilizes open-source LLMs (like Mistral, LLaMA 2) to replicate ChatGPT-like functionality â€“ without internet dependency, without API keys, and 100% free.

## ğŸš€ **Try VEXA Right Now!**

| ğŸ¯ **Immediate Use** | ğŸ¤– **Full AI Mode** |
|---------------------|---------------------|
| `python simple_vexa.py` | `python app/run_agent.py` |
| âœ… **Works now!** | âš ï¸ **Requires Ollama** |
| Interactive chat | Advanced AI responses |
| Calculator, date/time, files | + Web search |
| No setup needed | Setup: Install Ollama |

**No setup required - works immediately:**

```bash
# Interactive AI assistant (works now!)
python simple_vexa.py

# Or see a demonstration  
python demo.py
```

**Features available immediately:**
- ğŸ§® **Calculator**: Solve math problems
- ğŸ“… **Date/Time**: Current date and time info
- ğŸ“ **File Operations**: List files and directories  
- ğŸ¤– **Interactive Chat**: Real-time conversation interface
- ğŸ”’ **100% Offline**: No internet or API keys needed

**For full AI capabilities with web search and advanced reasoning, install Ollama (see setup below).**

## ğŸ’¡ Key Features

âœ… **Runs Locally**: Uses open-source LLMs via Ollama â€” no need for paid APIs  
ğŸ” **Web Search Tool**: Integrated with DuckDuckGo for real-time answers and current events  
ğŸ¤– **LangChain Agent**: Powered by the ReAct Agent with tool chaining  
ğŸ–¥ï¸ **Command-line & Web UI**: Interact via terminal or simple Gradio interface  
ğŸ”§ **Modular & Scalable**: Easily plug in your own tools (PDF reader, calculator, etc.)  
ğŸ”’ **Private & Offline-Ready**: Great for local development and secure environments  

## ğŸ§± Tech Stack

| Layer | Tool |
|-------|------|
| ğŸ’¬ **LLM** | Ollama â€“ Mistral / LLaMA 2 |
| ğŸ¤– **Agent Framework** | LangChain |
| ğŸŒ **Search Tool** | DuckDuckGo Search API |
| âš™ï¸ **Programming** | Python |
| ğŸŒ **Optional UI** | Gradio |

## ğŸ§ª How It Works

1. **Ollama** loads a local LLM (e.g., `mistral`) to serve as the brain of the agent
2. **LangChain** initializes an agent with custom tools like DuckDuckGo search
3. The user inputs a question via terminal or web UI
4. The agent decides whether to:
   - Answer directly using the LLM, or
   - Use a tool like search, then respond
5. Output is returned intelligently, step-by-step

## ğŸ“ Project Structure

```
vexa/
â”œâ”€â”€ ğŸ® demo.py              # Working demo (no Ollama required) â† START HERE!
â”œâ”€â”€ ğŸ–¥ï¸ simple_vexa.py       # Interactive mode (no Ollama) â† TRY THIS!
â”œâ”€â”€ ğŸ”§ setup.py             # Automated setup script
â”œâ”€â”€ ğŸ“Š test_components.py   # Component testing
â”œâ”€â”€ ğŸ“‹ STATUS.md            # Current project status
â”œâ”€â”€ ğŸ“– README.md            # This documentation
â”œâ”€â”€ âš¡ QUICKSTART.md        # Quick start guide
â”œâ”€â”€ ğŸ“‹ requirements.txt     # Python dependencies
â”œâ”€â”€ ğŸ”„ ai_agent.py          # Legacy simple version (requires Ollama)
â”œâ”€â”€ agent/                  # ğŸ§  Core agent package
â”‚   â”œâ”€â”€ __init__.py         # Package initialization
â”‚   â”œâ”€â”€ config.py          # Model and configuration settings
â”‚   â”œâ”€â”€ core.py            # Agent logic using LangChain
â”‚   â””â”€â”€ tools.py           # Tools like DuckDuckGo, calculator, etc.
â”œâ”€â”€ app/                   # ğŸ–¥ï¸ CLI applications
â”‚   â””â”€â”€ run_agent.py       # Full CLI interface (requires Ollama)
â””â”€â”€ ui/                    # ğŸŒ Web interface
    â””â”€â”€ web_ui.py          # Gradio web UI (requires Ollama)
```

## ğŸš€ Quick Start

### ğŸ¯ **Immediate Usage (No Setup Required)**

**Try VEXA right now without installing anything!**

```bash
# Interactive VEXA - chat interface with real tools
python simple_vexa.py

# Or demo mode - automated demonstration
python demo.py

# Test all components
python test_components.py
```

These versions work immediately with:
- âœ… Real calculator functionality
- âœ… Date/time queries  
- âœ… File operations
- âœ… Interactive chat interface
- âœ… No dependencies on external services

### ğŸ¤– **Full AI Experience (Requires Ollama)**

For the complete AI agent with LLM intelligence:

#### Prerequisites

1. **Install Ollama**:
   ```bash
   # Visit https://ollama.ai/ or install via:
   # Windows: Download from website
   # macOS: brew install ollama
   # Linux: curl -fsSL https://ollama.ai/install.sh | sh
   ```

2. **Pull a model**:
   ```bash
   ollama pull mistral
   # or
   ollama pull llama2
   ```

3. **Start Ollama server**:
   ```bash
   ollama serve
   ```

#### Installation

1. **Clone/Download the project**:
   ```bash
   git clone <repository-url>
   cd vexa
   ```

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run automated setup** (optional):
   ```bash
   python setup.py
   ```

### Usage Options

#### âš¡ **Option 1: Immediate Usage (Recommended)**

**No setup required - works right now!**

```bash
# Interactive mode with real tools
python simple_vexa.py

# Demo with automated examples  
python demo.py

# Verify everything works
python test_components.py
```

**Features available immediately:**
- ğŸ§® Calculator: "calculate 2+2", "what's 15*23?"
- ğŸ“… DateTime: "what time is it?", "current date"  
- ğŸ“ File ops: "list files", "show directory"
- â“ Help system: "help", "tools"

#### ğŸ¤– **Option 2: Full AI Agent (Requires Ollama)**

```bash
# Basic usage with default model (mistral)
python app/run_agent.py

# Use specific model
python app/run_agent.py --model llama2

# Single query mode
python app/run_agent.py --query "What's the weather like today?"

# Show available tools
python app/run_agent.py --tools-info

# Verbose mode for debugging
python app/run_agent.py --verbose
```

#### ğŸŒ **Option 3: Web Interface (Requires Ollama + Gradio)**

```bash
# Launch web UI with default settings
python ui/web_ui.py

# Custom port and model
python ui/web_ui.py --model llama2 --port 8080

# Share publicly (creates public link)
python ui/web_ui.py --share
```

Then open your browser to `http://localhost:7860` (or specified port).

#### ğŸ’» **Option 4: Python Integration**

```python
from agent import create_vexa_agent

# Create agent instance (requires Ollama)
agent = create_vexa_agent(model_name="mistral")

# Ask questions
response = agent.query("What's the current date?")
print(response["response"])

# Search the web
response = agent.query("Latest AI news 2025")
print(response["response"])
```

**Note**: Python integration requires Ollama to be running. For immediate usage without setup, use `python simple_vexa.py`.

## ğŸ› ï¸ Available Tools

- **ğŸ” Web Search**: Search the web using DuckDuckGo
- **ğŸ§® Calculator**: Perform mathematical calculations
- **ğŸ“… DateTime**: Get current date and time information  
- **ğŸ“ File Operations**: Basic file system operations
- **ğŸŒ¤ï¸ Weather**: Weather information (placeholder for demo)

## ğŸ’¬ Example Interactions

### **Simple Mode Examples** (Available Now)

```
ğŸ¤” Ask me anything: calculate 15 * 23
ğŸ¤– VEXA: Result: 345

ğŸ¤” Ask me anything: what time is it?
ğŸ¤– VEXA: Current time: 21:02:21

ğŸ¤” Ask me anything: list files
ğŸ¤– VEXA: Files in current directory: agent, demo.py, README.md, app, ui...

ğŸ¤” Ask me anything: help
ğŸ¤– VEXA: Available commands:
ğŸ§® Calculator: "calculate 2+2", "what's 15*23?"
ğŸ“… DateTime: "what time is it?", "current date"
ğŸ“ Files: "list files", "show directory"
```

### **Full AI Mode Examples** (With Ollama)

```
ğŸ¤” Ask me anything: What's the latest news about AI?
ğŸ¤– VEXA: Let me search for the latest AI news...
[Uses DuckDuckGo to find and summarize current AI news]

ğŸ¤” Ask me anything: Explain quantum computing in simple terms
ğŸ¤– VEXA: Quantum computing is a revolutionary approach to computation...
[Provides detailed, intelligent explanation]

ğŸ¤” Ask me anything: What's the weather in New York?
ğŸ¤– VEXA: I'll search for current weather information in New York...
[Searches web and provides current weather data]
```

## ğŸ”§ Customization

### Adding Custom Tools

Create your custom tool:

```python
from langchain_core.tools import Tool

def my_custom_function(input_text: str) -> str:
    return f"Processed: {input_text}"

custom_tool = Tool(
    name="my_tool",
    func=my_custom_function,
    description="Description of what this tool does"
)

# Add to agent
agent.add_tool(custom_tool)
```

### Configuration

Edit `agent/config.py` to modify:
- Default models
- Agent settings
- UI configuration
- Tool parameters

## ğŸš¨ Troubleshooting

### **Quick Solutions**

#### ğŸ¯ **Want to use VEXA right now?**
```bash
python simple_vexa.py    # Interactive mode - works immediately
python demo.py           # Demo mode - shows all features
```

#### â“ **Connection issues with main app?**
The full AI agent needs Ollama running. Use simple mode instead!

### **Common Issues**

1. **"Failed to initialize agent"** / **"Connection refused"**:
   - **Quick Fix**: Use `python simple_vexa.py` (works without Ollama)
   - **Full Fix**: Ensure Ollama is running: `ollama serve`
   - Check if model is installed: `ollama list`
   - Install required model: `ollama pull mistral`

2. **"Model not found"**:
   - Use `python app/run_agent.py --models` to see available models
   - Pull the model: `ollama pull <model-name>`

3. **Import errors** / **Module not found**:
   - Install dependencies: `pip install -r requirements.txt`
   - Test components: `python test_components.py`

4. **Web search not working**:
   - Check internet connection
   - DuckDuckGo might have rate limits
   - Use simple mode for offline functionality

5. **Web UI not loading**:
   - Install gradio: `pip install gradio>=4.0.0`
   - Check if port is available
   - Try a different port: `--port 8080`

### **What Works When**

| Feature | Simple Mode | Full AI Mode |
|---------|-------------|--------------|
| Calculator | âœ… Works now | âœ… Needs Ollama |
| DateTime | âœ… Works now | âœ… Needs Ollama |
| File Operations | âœ… Works now | âœ… Needs Ollama |
| Interactive Chat | âœ… Works now | âœ… Needs Ollama |
| Web Search | âŒ | âœ… Needs Ollama |
| AI Responses | Basic | âœ… Needs Ollama |
| Web UI | âŒ | âœ… Needs Ollama |

### Performance Tips

- **For faster responses**: Use smaller models like `mistral` or `orca-mini`
- **For better quality**: Use larger models like `llama2` or `llama3`
- **For coding tasks**: Use `codellama` model

## ğŸš€ Use Cases

- ğŸ‘¨â€ğŸ’» **Personal productivity assistant**
- ğŸ§‘â€ğŸ« **Study buddy for offline environments**  
- ğŸ”’ **Secure AI assistant for private organizations**
- ğŸ§ª **Testing LangChain agent logic without paid APIs**
- ğŸŒ **Local chatbot with web search capabilities**
- ğŸ“Š **Data analysis and calculations**

## ğŸ”’ Privacy & Security

- **100% Local Processing**: All queries processed on your machine
- **No Data Collection**: No telemetry or data sent to external servers
- **Offline Capable**: Works without internet (except for web search)
- **Open Source**: Full transparency of code and models

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is open source. See LICENSE file for details.

## ğŸ™ Acknowledgments

- **Ollama** for local LLM serving
- **LangChain** for agent framework
- **DuckDuckGo** for search capabilities
- **Gradio** for web interface
- **Open Source LLM Community** for the models

## ğŸ“ Support

If you encounter issues:

1. **Try simple mode first**: `python simple_vexa.py` (works without any setup)
2. **Check component status**: `python test_components.py` 
3. **Read status report**: Check `STATUS.md` for current project status
4. **Ensure all dependencies are installed**: `pip install -r requirements.txt`
5. **For full AI features**: Verify Ollama is running with the correct model
6. **Check GitHub issues** for similar problems

## ğŸ¯ **TL;DR - Just Want to Use VEXA?**

**Run this command right now:**
```bash
python simple_vexa.py
```

**You'll get:**
- âœ… Interactive AI assistant interface
- âœ… Working calculator, date/time, file operations
- âœ… No setup, no dependencies, no internet required
- âœ… Immediate functionality

**Want more features?** Install Ollama and use `python app/run_agent.py` for web search and advanced AI responses.

---

**Made with â¤ï¸ for the open-source AI community**
